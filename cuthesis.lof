\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces \textbf {Plus and Cross Polarisation.} The effect of the plus and cross polarisation of a GW on a ring of test particles. \cite {mckechan-thesis} }}{8}{figure.2.1}
\contentsline {figure}{\numberline {2.2}{\ignorespaces \textbf {The First Direct Detection of a Gravitational Wave.} The top panel shows the GW waveform with an inset cartoon of the state of the binary at four different phases of the binary inspiral. The bottom panel shows the Keplerian seperation distance in units of Schwarzschild radii ($R_s=\frac {2GM}{c^2}$ where $M$ is the total mass of the system). Also shown is the relative velocity of the black holes. \cite {150914-det-paper} }}{13}{figure.2.2}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Two identical schematics of a Michelson interferometer, each with a different naming convention. \cite {ifo_tech} }}{14}{figure.2.3}
\contentsline {figure}{\numberline {2.4}{\ignorespaces This schematic Michelson Interferometer shows our labelling convention for the different Electric fields. \cite {ifo_tech} }}{15}{figure.2.4}
\contentsline {figure}{\numberline {2.5}{\ignorespaces This plot shows how the detector output varies with the change in length of the interferoemeter arms. \cite {ifo_tech} }}{17}{figure.2.5}
\contentsline {figure}{\numberline {2.6}{\ignorespaces \textbf {Interferometer Antenna Pattern.} Here we see the antenna response on an interferometer with arms aligned with the x and y axes. The detector is most sensitive to GWs coming from perpendicular to the detector plane, while GWs approaching from within the detector plane but at an angle off-set from the arms by $\pi /4$ radians will be in a null of the detector. \cite {lrr-2009-2} }}{19}{figure.2.6}
\contentsline {figure}{\numberline {2.7}{\ignorespaces \textbf {ASD for LIGO Livingston Observatory.} Plotted in blue is the ASD for the LIGO Livingston Observatory as it was on the 20th August 2017. In grey we see the Gravitational Wave Interferometer Noise Curve (GWINC), a theoretical model of all the noise in the detector, as well as the O2 projected noise curve in orange. }}{20}{figure.2.7}
\contentsline {figure}{\numberline {2.8}{\ignorespaces \textbf {Noise Budget for LIGO Livingston Observatory.} Here we have the noise budget for the LIGO Livingston Observatory on 20th August 2017. The noise sources in LIGO detectors are descirbed in detail in \cite {noise_budget_martynov} and \cite {GW150914-detector}.}}{21}{figure.2.8}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces \textbf {BATSE gamma-ray light curves.} \cite {GRBprompt} }}{24}{figure.3.1}
\contentsline {figure}{\numberline {3.2}{\ignorespaces \textbf {BATSE GRB Fluence.} This plot shows the fluence (given by the colour of each point) and the sky position of each GRB detected by the BATSE mission. \cite {BATSE_dist} }}{26}{figure.3.2}
\contentsline {figure}{\numberline {3.3}{\ignorespaces \textbf {LogN-logP for BATSEVPO.} Here we plot the log of the number of GRBs against the log of the peak flux. The sample includes GRBs detected by BATSE and by PVO. The energy range for BATSE was 50-300keV, and the energy range for PVO was 100-2000keV. For uniformly distributed GRBs, we expect this plot to have a gradient of $-3/2$. The expected gradient is observed for high energy GRBs but not at lower energies. This suggests a limited distance to which GRBs can be observed. \textbf {cite \url {https://www.researchgate.net/figure/Distribution-log-N-log-P-for-a-combined-set-of-BATSEPVO-data-The-distributions-match_fig5_242389649}} \textbf {cite \url {https://www.nature.com/articles/366040a0.pdf}} }}{27}{figure.3.3}
\contentsline {figure}{\numberline {3.4}{\ignorespaces \textbf {T90 vs the spectral hardness ratio.} Here we plot the $T_{90}$ values and the spectral hardness ratio for the BATSE GRBs. The top panel shows a histogram of the T90 data, which clearly has two populations of GRBs, short and long. The main plot shows T90 against spectral hardness, which makes the two populations even more clear and shows that short GRBs have harder spectra than long GRBs. Those GRBs with the greatest ratio of energy in the X-ray to gamma ray band, generally those with a peak energy of less than 15 keV, are called \textit {X-ray flashes} (XRF). Those with comparable energy in the gamma-ray and X-ray band are called \textit {X-ray rich} (XRR) GRBs. All other GRBs are simply called GRBs. These different classes of GRBs are marked on the plot. Also shown is the 2 second dividing line between short and long GRBs. \textbf {cite What are Gamma-ray Bursts? Joshua Bloom}}}{29}{figure.3.4}
\contentsline {figure}{\numberline {3.5}{\ignorespaces \textbf {Break in spectrum due to jetting.} Here we see the optical light curves for the afterglow GRB 990510. A break in the spectrum is visible after approximately one day. \textbf {cite \url {https://iopscience.iop.org/article/10.1086/312282/fulltext/} }}}{32}{figure.3.5}
\contentsline {figure}{\numberline {3.6}{\ignorespaces \textbf {GRB170817A and GW170817.} Here we see that the a coherent conbination of the Hanford and Livingston strain data from GW170817 in the bottom panel. The top two panels shows the Fermi GRM curve in the 10-50keV and the 50-300keV range respectively. The INTEGRAL/SPI-ACS data is shown in the third plot. The background estimate for each detector is indicated by the red line. Note that the GRB was detected 1.7 seconds after the GW signal was detected. We can also see that Fermi detected a longer, softer signal in the 10-50 keV range, that lasted for a few seconds after the triggering pulse. \textbf {cite Gravitational Waves and Gamma-Rays from a Binary Neutron Star Merger: GW170817 and GRB 170817A} }}{37}{figure.3.6}
\contentsline {figure}{\numberline {3.7}{\ignorespaces \textbf {Glitch in the LIGO Livingston Observatory.} The top panel shows a time frequency map for the Livingston observatory data at the detection time of GW 170817. A glitch is clearly visible approximately 1.5 seconds before the end of the signal. Despite this the signal is still clearly visible. The bottom plot shows the raw strain data from the Livingston observatory. This data is bandpassed between 30 Hz and 2 kHz to emphasise the sensitive range of the detector. The grey curve (and right axis) shows the inverse Tukey window used to smoothly zero out the data around the glitch before the rapid reanalysis of the data. The blue curve shows the waveform model used to subtract the glitch from the data before measurements of the source's properties were made. \textbf {cite GW170817 observation from BNS} }}{39}{figure.3.7}
\contentsline {figure}{\numberline {3.8}{\ignorespaces \textbf {GW 170817 Detection.} Here we see time frequency maps of the LIGO Hanford and Livingston observatories, and the Virgo observatory at the detection time of GW 170817. This data has been whitened and independently observable noise sources have been subtracted, including a glitch in the Livingston data. The non-detection by Virgo significantly reduced the amount of the sky that the signal could have originated from. \textbf {cite GW170817 observation from BNS} }}{40}{figure.3.8}
\contentsline {figure}{\numberline {3.9}{\ignorespaces \textbf {Sky map for GW170817/GRB170817A.} Here we see the 90\% confidence sky localisation for the LIGO and Virgo collaborations in green, the GBM 90\% localisation in purple, and the annulus formed by Fermi and INTEGRAL timing information in grey. \textbf {cite Gravitational Waves and Gamma-Rays from a Binary Neutron Star Merger: GW170817 and GRB 170817A} }}{41}{figure.3.9}
\contentsline {figure}{\numberline {3.10}{\ignorespaces \textbf {NGC 4993.} Image of NGC 4993 taken in 1992 by the Anglo-Australian Observatory (left) and August 18th 2017 by the Las Cumbres Observatory (right). \textbf {cite https://www.nature.com/articles/nature24291/figures/2} }}{41}{figure.3.10}
\contentsline {figure}{\numberline {3.11}{\ignorespaces \textbf {Brightness/Luminosity against redshift.} Here we see the distribution of $E_\text {iso}$ and $L_\text {iso}$ against redshift for every GBM-detected GRB with a measured refshift. For GRBs with power law spectra, marked with a downward pointing arrow, this is taken to be an upper limit. This is because the spectra must have curvature, and so extrapolating a power law leads to an overestimation. The green dashed line shows the approximate detection threshold for the GBM. These plots show that GRB 170817A was much dimmer than any other detected GRB. [\textbf {cite GRB BNS paper}] }}{42}{figure.3.11}
\contentsline {figure}{\numberline {3.12}{\ignorespaces \textbf {Jet Structure Scenarios.} Three different scenarios that could explain the low luminosity of GRB 170817A. The first scenario is that a Top-hat jet was viewed off-axis. The second is that the jet is structured, with photons emitted further from the axis being lower energy and fewer in number, and viewed relatively far from the axis. The third scenario is that a uniform jet has a surrounding cocoon that emits lower energy photons, and it was these lower energy photons that were detected. \textbf {cite GRB BNS paper} }}{43}{figure.3.12}
\contentsline {figure}{\numberline {3.13}{\ignorespaces \textbf {Structured Jet.} Left panel: A pseudocolour density image of the simulation used to compute the afterglow curves [\textbf {citation in afterglow paper}]. The low density core of the jet is the blue region near the middle. The orange and green region around the core is the slow moving wings. Top right panel: Here we see the 3 GHz flux detected from different parts of the structured jet as time progresses. The angle is relative jet axis, so the blue curve is the core of the jet, the orange curve is the fast wings of the jet, the orange curve is the material moving along the line of sight (an angle of about $33^\circ $ in this case), and the pink and brown curves correspond to large angles, that do not contribute much to eh observed flux. Bottom right panel: The distribution of energy as a function of angular separation from the jet. \textbf {cite GRB afterglow paper paper} }}{45}{figure.3.13}
\contentsline {figure}{\numberline {3.14}{\ignorespaces \textbf {Jet Model Comparison.} Here we see a comparison of the best fit for the structured jet, Top-hat jet seen off-axis, and isotropic models. The afterglow's measured flux density at 3 GHz is shown by the blue symbols (though the fits were performed with multiwavelength data). The inset shows the best fit isotropic energy and Lorentz factor for each model as a function of viewing angle. The arrows show the position of the observer for the structured and Top-hat jet models. \textbf {cite GRB afterglow paper paper} }}{46}{figure.3.14}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces \textbf {Null Stat Cut.} Here we plot the coherent SNR against the null SNR. The blue crosses are background triggers. The red pluses are signal injections. The black line is the veto line, with all triggers in the shaded region above the line being discarded. The green line indicates the expected SNR for optimally oriented injections. The magenta and cyan lines show 1 and 2 sigma errors on the green line. }}{69}{figure.4.1}
\contentsline {figure}{\numberline {4.2}{\ignorespaces \textbf {PyGRB Sky Grid.} Here we see an example of a full search grid used by PyGRB, indicated by the blue dots, and a reduced sky grid parsed by PyGRB in the case of a two detector search using the Hanford and Livingston detectors, the empty circles labeled 'parsed'. The parsed circles do not form a line due to the parsing routine, but this has no effect on analysis. \textbf {cite Andrew's paper}}}{73}{figure.4.2}
\contentsline {figure}{\numberline {4.3}{\ignorespaces \textbf {PyGRB Workflow.} The workflow starts in two parallel branches, one that runs the injections jobs, and one that analyses the background and onsource. }}{75}{figure.4.3}
\contentsline {figure}{\numberline {4.4}{\ignorespaces \textbf {P-value for each GRB.} This is the p-value distribution for the 41 GRBs other than GRB 170817A. The GRBs with no trigger in the onsource window have upper and lower limits on the p-value. The upper limit is a p-value of 1. The lower limit is the fraction of offsource trials that also had no trigger. The distribution lays within the $2\sigma $ range, shown by the upper and lower dotted lines. }}{77}{figure.4.4}
\contentsline {figure}{\numberline {4.5}{\ignorespaces \textbf {Cumulative exclusion distance.} This is the cumulative $90\%$ exclusion distance for every GRB analysed by PyGRB except GRB170817A. The $90\%$ exclusion distance is the distance at which $90\%$ of injected simulated signals are recovered with a greater coherent SNR than the loudest trigger in the onsource. }}{78}{figure.4.5}
\contentsline {figure}{\numberline {4.6}{\ignorespaces \textbf {Cumulative Rate of BNS and short GRB Events.} The magenta lines show the 90\% confidence bounds for joint GRB-GW event as a function of redshift. This was calculated using the 41 non-detections and single detection by PyGRB during O2. The black line and the grey region shows the estimated BNS merger rate $1210^{+3230}_{-1040}$. In green is shown the estimated Fermi detection rate and its 90\% confidence region [\textbf {cite howell et al}]. The measured redshifts of every short GRB apart from GRB 170817A are shown in brown. The gold sample refers to those GRBs that were localised to near a host galaxy, making the redshift measurement more reliable that short GRBs measured more distant from a host galaxy. Our results are compatible with both the Fermi-GBM observed rate and the predicted BNS merger rate. }}{80}{figure.4.6}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces \textbf {X-pipeline Time-Frequency Map} This figure shows a time-frequency map from X-pipeline for a $1.4-10 M_\odot $ NSBH merger. The top figure shows the $E_+$ energy and the bottom figure shows the top 1\% of pixels. [\textbf {cite xp paper}] }}{86}{figure.6.1}
\contentsline {figure}{\numberline {6.2}{\ignorespaces \textbf {X-pipeline Cut} This figure shows an example of an X-pipeline cut. The axes show two of the statistics that X-pipeline calculates. Specifically, the x-axis shows the coherent null energy and the y-axis shows the incoherent null energy (see section \ref {sec:xcuts} for more details on these statistics). The red squares show simulated GW signals, and the crosses show background triggers. The colour bar shows the base 10 logarithm of the significance of each trigger. We can see that in this case, the cut eliminates more of the noise and only a few signals. [\textbf { cite X-pipeline paper }] }}{87}{figure.6.2}
\contentsline {figure}{\numberline {6.3}{\ignorespaces \textbf {Cumulative Distribution of p-values.} Here we plotted the p-values for every GRB analysed by X-pipeline in O2 apart from GRB 170817A. Also plotted is the expected distribution and the $2\sigma $ deviation. The results are consistent with the no-signal hypothesis. [\textbf {cite O2 GRB paper}]}}{94}{figure.6.3}
\contentsline {figure}{\numberline {6.4}{\ignorespaces \textbf {Cumulative Distribution of Exclusion Distance.} Here we plotted the 90\% exclusion distance for every GRB analysed by X-pipeline in O2 apart from GRB 170817A. This is the distance to which 90\% of injections can be recovered with a significance greater than the loudest event in the on-source. [\textbf {cite O2 GRB paper}] }}{95}{figure.6.4}
\contentsline {figure}{\numberline {6.5}{\ignorespaces \textbf {Schematic Decision Tree.} To determine if a trigger is a signal or noise event the tree makes a series of cuts on the attributes x[N]. If the inequality in a node is true, then the next node is the branch to the left. Otherwise the next node is the one to the right. The properties of the tree, such as the number of layers it has, are set by the user (see section \ref {sec:opt}). }}{99}{figure.6.5}
\contentsline {figure}{\numberline {6.6}{\ignorespaces \textbf {Visualising the Classifier.} In the top plot you can see the value for log(Enull) and log(Inull) for all the signal and background training data used to build the classifier. We chose one of these events at random (indicated by the star) and varied Enull and Inull to see how it changed the MVA score, indicated by the colour in the bottom plot. As we can see, increasing Inull and decreasing Enull leads to the event being more likely to be classed as a signal. This is akin to the X-pipeline cut shown in fig.\ref {fig:xcuts}. }}{100}{figure.6.6}
\contentsline {figure}{\numberline {6.7}{\ignorespaces \textbf {Removing WNB and Cusp Waveforms from Training Set.} Here we plot the percentage change in 50\% upper limit injection scale per waveform after removing WNB and Cusp waveforms from the training set. The sensitivity to most waveforms drops, but by less than 1\%. This shows that the MVA is able to detect GW morphologies that it has not been trained on. }}{104}{figure.6.7}
\contentsline {figure}{\numberline {6.8}{\ignorespaces \textbf {Effect of Hyperparameter Optimisation.} Here we see the effects of optimisation on the 50\% upper limit injection scale. The top panel showing the absolute values and the bottom panel showing the percentage change. The benefits of optimising the hyperparameters is no more than a $\sim 3\%$ improvement in sensitivity when compared to the default settings of the TMVA boosted decision tree classifier. }}{107}{figure.6.8}
\contentsline {figure}{\numberline {6.9}{\ignorespaces \textbf {MVA Improvement.} Here we see the effects of using the MVA on the 50\% upper limit injection scale for the same GRB that was used for optimisation. The top panel showing the absolute values and the bottom panel showing the percentage change. We can see that the MVA outperforms X-pipeline on every waveform. As this was the GRB used to optimise the hyperparamters, it cannot be guaranteed that these results will hold for other GRB analyses. }}{108}{figure.6.9}
\contentsline {figure}{\numberline {6.10}{\ignorespaces \textbf {X-pipeline and XTMVA ADI-a 50\% Injection Scale Upper Limit by GRB.} Here we plot the sensitivity to the ADI-a waveform of both X-pipeline and XTMVA. This plot shows that XTMVA is more stable and in general more sensitive than X-pipeline to this waveform. }}{110}{figure.6.10}
\contentsline {figure}{\numberline {6.11}{\ignorespaces \textbf {X-pipeline and XTMVA CSG 50\% Injection Scale Upper Limit by GRB.} Here we plot the sensitivity to the 150 Hz circular sine gaussian waveform of both X-pipeline and XTMVA. This plot shows that XTMVA is more stable and in more sensitive than X-pipeline to this waveform. }}{111}{figure.6.11}
\contentsline {figure}{\numberline {6.12}{\ignorespaces \textbf {Median 50\% Injection Scale Upper Limit by Waveform.} Here we plot the median sensitivity to each waveform of both X-pipeline and XTMVA. Overall, XTMVA is more sensitive, especially to shorter waveforms such as sine gaussians. Apart from ADI-a, the MVA is worse than X-pipeline for long waveforms, though the difference is small. If the MVA could use the long injection code that X-pipeline uses, it is reasonable to expect that the MVA would also outperform X-pipeline for long waveforms as well. }}{112}{figure.6.12}
\contentsline {figure}{\numberline {6.13}{\ignorespaces \textbf {XTMVA p-values.} Here we have plotted the p-values for 13 of the GRBs analysed with the MVA. The blue triangles indicate the p-value reported by the MVA, the black dotted lines show the expected distribution and a $2\sigma $ deviation. Two GRBs that were analysed were left out from this plot: GRB 170817A as it had a known GW counterpart and E264930 as it was used to tune the hyperparameters. The analysis shows some bias towards low p-values. In particular, two out of the 13 analysed GRBs have a p-value of $\sim 1\%$. This can be compared to figure \ref {fig:xpvalue} which shows the X-pipeline p-values for O2. In particular, X-pipeline did not have the same bias towards low p-values that X-pipeline does.}}{113}{figure.6.13}
\contentsline {figure}{\numberline {6.14}{\ignorespaces \textbf {Cumulative Distribution of Exclusion Distance.} Here we plotted the XTMVA 90\% exclusion distance for the 13 GRBs in the results set. This is the distance to which 90\% of injections can be recovered with a significance greater than the loudest event in the on-source. }}{114}{figure.6.14}
\contentsline {figure}{\numberline {6.15}{\ignorespaces \textbf {Detection Efficiency Curve without Generalised Clustering.} This is the detection efficiency curve for an XTMVA analysis without generalised clustering. The x-axis shows the energy in the injected waveform and the y-axis shows the fraction of injections detected. This plot shows that at low amplitude no injections are found, while for very loud injections there is almost a 100\% detection efficiency. }}{117}{figure.6.15}
\contentsline {figure}{\numberline {6.16}{\ignorespaces \textbf {Detection Efficiency Curve with Generalised Clustering.} This is the detection efficiency curve for an XTMVA analysis using generalised clustering. The x-axis shows the energy in the injected waveform and the y-axis shows the fraction of injections detected. We can see that at low amplitude some injections are being found, even to very low amplitude. We can also see that some very loud injections are being missed, despite the fact that close to 100\% of some lower energy injection sets are being found. }}{118}{figure.6.16}
\contentsline {figure}{\numberline {6.17}{\ignorespaces \textbf {Time-Frequency Box Size.} Here we have a histogram of the time-frequency box size of triggers in the signal training set for an analysis with generalised clustering and without. While the generalised clustering run has a lot more triggers overall, most of the extra triggers have small time-frequency boxes. }}{118}{figure.6.17}
\contentsline {figure}{\numberline {6.18}{\ignorespaces \textbf {Time of Peak Energy for Signal Training Set Triggers.} This is a histogram of the time of peak energy for each trigger in the signal training set. It clearly shows that a small time window contributes most of the signal training set. This strongly suggests a glitch contaminating the signal training set. }}{119}{figure.6.18}
