\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces \textbf {Null Stat Cut.} Here we plot the coherent SNR against the null SNR. The blue crosses are background triggers. The red pluses are signal injections. The black line is the veto line, with all triggers in the shaded region above the line being discarded. The green line indicates the expected SNR for optimally oriented injections. The magenta and cyan lines show 1 and 2 sigma errors on the green line. }}{19}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces \textbf {Xpipeline Time-Frequency Map} This figure shows a time-frequency map from Xpipeline for a $1.4-10M_\odot $ NSBH merger. The top figure shows the $E_+$ energy and the bottom figure shows the top 1\% of pixels. }}{26}
\contentsline {figure}{\numberline {5.2}{\ignorespaces \textbf {Xpipeline Cut} This figure shows Xpipeline making a cut to eliminate many spurious signals. }}{27}
\contentsline {figure}{\numberline {5.3}{\ignorespaces \textbf {A decision tree example} To determine if a trigger is a signal or noise event the tree makes a series of cuts on the attributes x[N]. If the inequality in a node is true, then the next node is the branch to the left. Otherwise the next node is the one to the right. }}{35}
\contentsline {figure}{\numberline {5.4}{\ignorespaces \textbf {Visualising the Classifier} In the bottom plot you can see the value for log(Enull) and log(Inull) for all the signal and background training data used to build the classifier. We chose one of these events at random (indicated by the star) and varied Enull and Inull to see how it changed the MVA score, indicated by the colour in the top plot. As you can see, increasing Inull and decreasing Enull leads to the event being more likely to be classed as a signal. This is akin to the xpipeline cut shown in fig.5.2\hbox {}. }}{36}
